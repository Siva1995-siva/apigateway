1.How do you reduce latency caused by multiple microservice hops?
Optimize Inter-Service Communication
Use Asynchronous Communication: Where possible, use asynchronous communication methods (e.g., message queues) to decouple services and avoid blocking calls that can increase latency.

Below is a complete, practical example showing Java Microservices using Feign Client + Kafka for asynchronous communication.
We will implement:

‚úî Order Service ‚Üí sends an event to Kafka
‚úî Payment Service ‚Üí consumes the event from Kafka
‚úî Communication between services is async via Kafka
‚úî Feign client is used for synchronous inter-service calls (if needed)

üß± Architecture Overview
 Order Service                      Kafka                       Payment Service
------------------             --------------              -----------------------
REST API ---> Feign (optional)  order-topic  ---> Consumer ---> Process Payment
                   |
                   ---> Kafka Producer
‚úÖ 1. Common Dependencies (Spring Boot)
pom.xml


        <artifactId>spring-boot-starter-web</artifactId>

    <!-- Feign Client -->
    
        <artifactId>spring-cloud-starter-openfeign</artifactId
    <!-- Kafka -->
    
        <artifactId>spring-kafka</artifactId>
    <!-- For JSON serialization -->
    <artifactId>jackson-databind</artifactId>
    
</dependencies>
‚úÖ 2. Order Service ‚Äî Sends Kafka Message
application.yml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
OrderCreatedEvent.java
@Data
@AllArgsConstructor
@NoArgsConstructor
public class OrderCreatedEvent {
    private String orderId;
    private Double amount;
    private String customerId;
}
KafkaProducerConfig.java
@Configuration
public class KafkaProducerConfig {

    @Bean
    public ProducerFactory<String, OrderCreatedEvent> producerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        return new DefaultKafkaProducerFactory<>(config);
    }

    @Bean
    public KafkaTemplate<String, OrderCreatedEvent> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
OrderController.java
@RestController
@RequestMapping("/orders")
@RequiredArgsConstructor
public class OrderController {

    private final KafkaTemplate<String, OrderCreatedEvent> kafkaTemplate;

    @PostMapping
    public String createOrder(@RequestBody OrderCreatedEvent event) {
        kafkaTemplate.send("order-topic", event.getOrderId(), event);
        return "Order Created & Event Published!";
    }
}
üéØ Optional: Feign Client (Sync Call Between Services)
Sometimes OrderService may need to synchronously fetch data before publishing:

CustomerClient.java
@FeignClient(name = "customer-service", url = "http://localhost:8082")
public interface CustomerClient {
    @GetMapping("/customers/{id}")
    CustomerDTO getCustomer(@PathVariable String id);
}
Enable Feign
@SpringBootApplication
@EnableFeignClients
public class OrderServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(OrderServiceApplication.class, args);
    }
}
‚úÖ 3. Payment Service ‚Äî Kafka Consumer
application.yml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: payment-consumers
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
    properties:
      spring.json.trusted.packages: "*"
KafkaConsumerConfig.java
@Configuration
public class KafkaConsumerConfig {

    @Bean
    public ConsumerFactory<String, OrderCreatedEvent> consumerFactory() {
        Map<String, Object> config = new HashMap<>();

        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        config.put(ConsumerConfig.GROUP_ID_CONFIG, "payment-consumers");
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        config.put(JsonDeserializer.TRUSTED_PACKAGES, "*");

        return new DefaultKafkaConsumerFactory<>(config, new StringDeserializer(),
                new JsonDeserializer<>(OrderCreatedEvent.class));
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, OrderCreatedEvent> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, OrderCreatedEvent> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}
PaymentEventListener.java
@Service
public class PaymentEventListener {

    @KafkaListener(topics = "order-topic", groupId = "payment-consumers")
    public void handleOrderCreated(OrderCreatedEvent event) {
        System.out.println("Payment Service received event: " + event);
        // Process payment here
    }
}
üß™ Test the Flow
1Ô∏è‚É£ Start Kafka broker
(Using Docker or local installation)

2Ô∏è‚É£ Start Order Service (port 8081)
3Ô∏è‚É£ Start Payment Service (port 8082)
4Ô∏è‚É£ POST to create an order:
POST http://localhost:8081/orders

{
  "orderId": "ORD123",
  "amount": 999.0,
  "customerId": "CUS001"
}
-------------------------------------------------------------------------------------------------------------------------------
Minimize Service Calls: Reduce the number of inter-service calls by aggregating data where possible or combining multiple requests into a single one.
Below is a clean, practical example of how to minimize service calls in Java microservices using:

‚úÖ Caching (Spring Cache + Redis)
‚úÖ Bulk/Batch requests instead of multiple small calls
‚úÖ Feign client optimization
‚úÖ Aggregation service pattern
‚úÖ Circuit breaker (Resilience4j)

You can mix these techniques in real systems to drastically reduce cross-service traffic.

1Ô∏è‚É£ Technique A: Caching ‚Äî Avoid Repeated Remote Calls
‚û§ Use Case:

OrderService calling CustomerService repeatedly for same customer details.

Step 1 ‚Äî Enable Cache (Redis or In-Memory)
pom.xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-cache</artifactId>
</dependency>

<!-- Optional: Redis cache for distributed caching -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>

Application
@SpringBootApplication
@EnableFeignClients
@EnableCaching
public class OrderServiceApplication {}

Step 2 ‚Äî Cache Customer Lookup
CustomerClient.java (Feign)
@FeignClient(name = "customer-service", url = "http://localhost:8082")
public interface CustomerClient {

    @GetMapping("/customers/{id}")
    CustomerDTO getCustomer(@PathVariable String id);
}

CustomerServiceWrapper.java
@Service
@RequiredArgsConstructor
public class CustomerServiceWrapper {

    private final CustomerClient customerClient;

    @Cacheable(value = "customerCache", key = "#customerId")
    public CustomerDTO getCustomer(String customerId) {
        return customerClient.getCustomer(customerId);
    }
}


üí° Now repeated calls like getCustomer("C001") hit cache instead of calling the microservice.

2Ô∏è‚É£ Technique B: Batch / Bulk Calls ‚Äî Replace N Calls with 1 Call
Instead of:

GET /customers/1
GET /customers/2
GET /customers/3

‚Üí Combine into a single call:

GET /customers?ids=1,2,3

CustomerClient.java
@FeignClient(name = "customer-service")
public interface CustomerClient {

    @GetMapping("/customers")
    List<CustomerDTO> getCustomers(@RequestParam List<String> ids);
}

OrderService.java (Bulk Fetch)
@Service
@RequiredArgsConstructor
public class OrderService {

    private final CustomerClient customerClient;

    public void processOrders(List<Order> orders) {

        List<String> customerIds = orders.stream()
                .map(Order::getCustomerId)
                .distinct()
                .toList();

        // Single service call instead of N calls
        List<CustomerDTO> customers = customerClient.getCustomers(customerIds);

        Map<String, CustomerDTO> map = customers.stream()
                .collect(Collectors.toMap(CustomerDTO::getId, c -> c));

        orders.forEach(order ->
                order.setCustomer(map.get(order.getCustomerId())));
    }
}


üìâ Service calls reduced by up to 90% depending on dataset.

3Ô∏è‚É£ Technique C: Aggregation Service ‚Äî Call Multiple Services Once

Instead of a client calling:

ProductService

CustomerService

InventoryService

‚Üí Create an aggregator microservice (API Gateway pattern).

AggregatorController.java
@RestController
@RequiredArgsConstructor
@RequestMapping("/order-summary")
public class AggregationController {

    private final ProductClient productClient;
    private final CustomerClient customerClient;
    private final InventoryClient inventoryClient;

    @GetMapping("/{orderId}")
    public OrderSummaryDTO getSummary(@PathVariable String orderId) {

        OrderDTO order = productClient.getOrder(orderId);

        CustomerDTO customer = customerClient.getCustomer(order.getCustomerId());
        InventoryDTO inventory = inventoryClient.getStock(order.getProductId());

        return new OrderSummaryDTO(order, customer, inventory);
    }
}


üí° The client sees one API call, while aggregator handles the multi-service orchestration.

4Ô∏è‚É£ Technique D: Use Resilience4j for Fallback (Avoid Retry Storms)

Add dependency:

<dependency>
    <groupId>io.github.resilience4j</groupId>
    <artifactId>resilience4j-spring-boot3</artifactId>
</dependency>

CustomerServiceWrapper with Circuit Breaker
@Service
@RequiredArgsConstructor
public class CustomerServiceWrapper {

    private final CustomerClient customerClient;

    @Cacheable(value = "customerCache", key = "#customerId")
    @CircuitBreaker(name = "customerCB", fallbackMethod = "fallbackCustomer")
    public CustomerDTO getCustomer(String customerId) {
        return customerClient.getCustomer(customerId);
    }

    public CustomerDTO fallbackCustomer(String customerId, Throwable t) {
        return new CustomerDTO(customerId, "Unknown", "N/A");
    }
}


üõ°Ô∏è This prevents microservice overload and protects from cascading failures.

5Ô∏è‚É£ Technique E: Local Data Replication (CQRS Materialized Views)

For heavy-read microservices:

Replicate necessary data (event-driven)

Avoid remote service call entirely

Example:

@KafkaListener(topics = "customer-updates")
public void updateLocalReadDB(CustomerDTO dto) {
    repository.save(dto);
}


Now your reads come from the local database, not another service.

üéØ Summary ‚Äî Best Ways to Minimize Service Calls
Technique	Benefit
Caching	Avoid duplicate calls entirely
Bulk/Batch API	Replace multiple sequential calls with one
Aggregator service	Client makes single request
Circuit breaker	Avoid retry storms when service is down
Local replication (CQRS)	Remove cross-service call in read-heavy scenarios
---------------------------------------------------------------------------------------------------
Efficient Data Formats: Use compact and efficient data serialization formats like Protocol Buffers (protobuf) or Avro instead of verbose formats like JSON or XML to reduce data size and parsing time.
Below are clear, production-style coding examples showing how Java microservices use efficient data formats such as:

‚úÖ Protobuf (Protocol Buffers)
‚úÖ Avro (with Kafka)
‚úÖ MessagePack (JSON but compressed/binary)
‚úÖ CBOR (binary JSON)

Efficient formats reduce payload size ‚Üí fewer bytes ‚Üí faster microservice communication.

1Ô∏è‚É£ Protocol Buffers (Protobuf) ‚Äì Most Efficient for Microservices

Protobuf is Google‚Äôs binary format.
‚ö° Very small payload
‚ö° Very fast serialization/deserialization
‚ö° Perfect for Feign/REST/Kafka microservices

Step 1: Define .proto schema

üìå user.proto

syntax = "proto3";

option java_package = "com.example.proto";
option java_outer_classname = "UserProto";

message User {
  string id = 1;
  string name = 2;
  int32 age = 3;
}

Step 2: Add Maven Plugins
<dependency>
    <groupId>com.google.protobuf</groupId>
    <artifactId>protobuf-java</artifactId>
    <version>3.25.3</version>
</dependency>

<plugin>
    <groupId>org.xolstice.maven.plugins</groupId>
    <artifactId>protobuf-maven-plugin</artifactId>
    <version>0.6.1</version>
    <configuration>
        <protocArtifact>
            com.google.protobuf:protoc:3.25.3:exe:${os.detected.classifier}
        </protocArtifact>
        <outputDirectory>${project.build.directory}/generated-sources/protobuf/java</outputDirectory>
    </configuration>
    <executions>
        <execution>
            <goals>
                <goal>compile</goal>
            </goals>
        </execution>
    </executions>
</plugin>

Step 3: Using Protobuf in REST
Controller (Return Protobuf Bytes)
@RestController
@RequestMapping("/users")
public class UserController {

    @GetMapping(value="/{id}", produces = "application/x-protobuf")
    public byte[] getUser(@PathVariable String id) {

        UserProto.User user = UserProto.User.newBuilder()
                .setId(id)
                .setName("John")
                .setAge(25)
                .build();

        // Serialize to binary
        return user.toByteArray();
    }
}


‚ö° Payload size is 90% smaller than JSON.

Step 4: Feign Client Calling Protobuf
Feign Client
@FeignClient(name = "user-service")
public interface UserClient {

    @GetMapping(value = "/users/{id}", consumes = "application/x-protobuf")
    UserProto.User getUser(@PathVariable("id") String id);
}

Decoder/Encoder Config
@Configuration
public class ProtobufConfig {

    @Bean
    public Decoder protobufDecoder() {
        return (response, type) -> UserProto.User.parseFrom(response.body().asInputStream());
    }

    @Bean
    public Encoder protobufEncoder() {
        return (object, bodyType, requestTemplate) -> {
            requestTemplate.body(((UserProto.User) object).toByteArray(), StandardCharsets.UTF_8);
        };
    }
}

2Ô∏è‚É£ Avro ‚Äî Best With Kafka (Compact + Schema Evolution)
Avro schema: user.avsc
{
  "type": "record",
  "name": "User",
  "namespace": "com.example.avro",
  "fields": [
    {"name": "id", "type": "string"},
    {"name": "name", "type": "string"},
    {"name": "age", "type": "int"}
  ]
}

Maven Dependencies
<dependency>
    <groupId>org.apache.avro</groupId>
    <artifactId>avro</artifactId>
</dependency>

Kafka Producer (Avro)
User user = User.newBuilder()
        .setId("U1")
        .setName("John")
        .setAge(25)
        .build();

ProducerRecord<String, User> record = new ProducerRecord<>("user-topic", "U1", user);
producer.send(record);

Kafka Consumer (Avro)
@KafkaListener(topics = "user-topic")
public void consume(User user) {
    System.out.println("Received: " + user);
}


‚úî Best for large scale event-driven microservices
‚úî Smaller than JSON
‚úî Backward-compatible schemas

3Ô∏è‚É£ MessagePack ‚Äî Binary JSON with Small Payload

üëç Very easy drop-in replacement for JSON.
üëç Faster than Jackson JSON.

Dependency
<dependency>
    <groupId>org.msgpack</groupId>
    <artifactId>msgpack-core</artifactId>
    <version>0.9.8</version>
</dependency>

Serialize/Deserialize Example
MessageBufferPacker packer = MessagePack.newDefaultBufferPacker();
packer.packString("John");
packer.packInt(25);
packer.close();

byte[] bytes = packer.toByteArray();

// Deserialize
MessageUnpacker unpacker = MessagePack.newDefaultUnpacker(bytes);
String name = unpacker.unpackString();
int age = unpacker.unpackInt();
unpacker.close();


üìâ Payload size ‚âà 50% smaller than JSON.

4Ô∏è‚É£ CBOR ‚Äî Compressed JSON for REST APIs
Dependency
<dependency>
    <groupId>com.fasterxml.jackson.dataformat</groupId>
    <artifactId>jackson-dataformat-cbor</artifactId>
</dependency>

REST Controller With CBOR
@RestController
@RequestMapping("/items")
public class ItemController {

    @GetMapping(value = "/{id}", produces = "application/cbor")
    public Item getItem(@PathVariable String id) {
        return new Item(id, "Laptop", 1200.0);
    }
}

Feign Client (CBOR)
@FeignClient(name = "item-service")
public interface ItemClient {

    @GetMapping(value="/items/{id}", consumes = "application/cbor")
    Item getItem(@PathVariable String id);
}

üìå Summary ‚Äî When to Use What?
Format	Best For	Benefit
Protobuf	REST + gRPC	Fastest, smallest
Avro	Kafka events	Schema evolution
MessagePack	Lightweight REST	Faster/smaller than JSON
CBOR	REST APIs	Binary JSON, compact
-------------------------------------------------------------------------------------------------------------
at Multiple Levels: Implement caching at the service level, database level, and even at the client-side where applicable to reduce redundant data retrievals.

üß± Multi-Level Caching in API Gateway

‚úî L1 Cache (In-Memory / Caffeine) ‚Äì extremely fast, inside the gateway service
‚úî L2 Cache (Redis / Distributed Cache) ‚Äì shared across gateway instances
‚úî L3 Cache (Downstream microservices) ‚Äì optional microservice caching

Gateway flow:

Client ‚Üí API Gateway
        ‚Üì
     L1 Cache
        ‚Üì        (if miss)
     L2 Cache (Redis)
        ‚Üì        (if miss)
  Call Downstream Microservice


Gateway populates caches at each level.

1Ô∏è‚É£ Add Dependencies
pom.xml
<dependencies>
    <!-- Spring WebFlux Gateway -->
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-gateway</artifactId>
    </dependency>

    <!-- Redis Cache -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-redis</artifactId>
    </dependency>

    <!-- Caffeine In-Memory Cache -->
    <dependency>
        <groupId>com.github.ben-manes.caffeine</groupId>
        <artifactId>caffeine</artifactId>
    </dependency>

    <!-- Feign Client to Call Microservices -->
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-openfeign</artifactId>
    </dependency>
</dependencies>

2Ô∏è‚É£ L1 Cache (Caffeine In-Memory Cache at API Gateway)
@Configuration
public class CacheConfig {

    @Bean
    public Cache<String, String> inMemoryCache() {
        return Caffeine.newBuilder()
                .maximumSize(5000)
                .expireAfterWrite(Duration.ofMinutes(3))
                .build();
    }
}

3Ô∏è‚É£ L2 Cache (Redis Cache at Gateway)
spring:
  redis:
    host: localhost
    port: 6379

Redis Utility
@Service
@RequiredArgsConstructor
public class RedisCacheService {

    private final StringRedisTemplate redis;

    public void put(String key, String value) {
        redis.opsForValue().set(key, value, Duration.ofMinutes(10));
    }

    public String get(String key) {
        return redis.opsForValue().get(key);
    }
}

4Ô∏è‚É£ Feign Client (Gateway ‚Üí Downstream Microservices)
@FeignClient(name = "product-service", url = "http://localhost:8082")
public interface ProductClient {

    @GetMapping("/products/{id}")
    String getProduct(@PathVariable String id);
}

5Ô∏è‚É£ API Gateway Custom Filter With Multi-Level Cache

This filter checks:

L1 (Caffeine)

L2 (Redis)

Calls microservice

Writes back to both caches

ProductCacheGatewayFilter.java
@Component
@RequiredArgsConstructor
public class ProductCacheGatewayFilter implements GatewayFilter {

    private final Cache<String, String> inMemoryCache;
    private final RedisCacheService redisCache;
    private final ProductClient productClient;

    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {

        String productId = exchange.getRequest()
                                   .getPath()
                                   .value()
                                   .replace("/products/", "");

        String cachedValue = inMemoryCache.getIfPresent(productId);

        if (cachedValue != null) {
            return writeResponse(exchange, cachedValue);
        }

        String redisValue = redisCache.get(productId);
        if (redisValue != null) {
            inMemoryCache.put(productId, redisValue);
            return writeResponse(exchange, redisValue);
        }

        // MISS BOTH ‚Üí Call downstream microservice
        return Mono.fromCallable(() -> productClient.getProduct(productId))
                   .flatMap(response -> {
                       // Write back to caches
                       inMemoryCache.put(productId, response);
                       redisCache.put(productId, response);
                       return writeResponse(exchange, response);
                   });
    }

    private Mono<Void> writeResponse(ServerWebExchange exchange, String body) {
        exchange.getResponse().getHeaders().setContentType(MediaType.APPLICATION_JSON);
        DataBuffer buffer = exchange.getResponse()
                                    .bufferFactory()
                                    .wrap(body.getBytes(StandardCharsets.UTF_8));
        return exchange.getResponse().writeWith(Mono.just(buffer));
    }
}

6Ô∏è‚É£ Route Configuration to Use the Cache Filter
@Configuration
public class GatewayRoutes {

    @Bean
    public RouteLocator customRouteLocator(RouteLocatorBuilder builder,
                                           ProductCacheGatewayFilter cacheFilter) {
        return builder.routes()
                .route("product-route", r -> r
                        .path("/products/**")
                        .filters(f -> f.filter(cacheFilter))
                        .uri("http://localhost:8082"))
                .build();
    }
}

7Ô∏è‚É£ Response Flow
First Request

‚úî Not found in L1 ‚Üí Not found in L2 ‚Üí Call product-service
‚úî Cache both

Second Request

‚úî Hit L1 ‚Üí blazing fast
(no Redis, no microservice call)

After a few minutes

‚úî L1 expires, Redis still valid ‚Üí Redis ‚Üí Put back into L1

üìå Optional: L3 Cache (Downstream Microservices)

In Product Service:

@Service
public class ProductService {

    @Cacheable("productCache")
    public Product getProduct(String id) {
        // DB query
    }
}


Now the full chain is cached:

Gateway L1 ‚Üí Gateway L2 ‚Üí Microservice Cache ‚Üí Database

‚úî Final Result: Highly Optimized API Gateway

L1 Cache (Caffeine) = 50‚Äì100√ó faster than a network call

L2 Cache (Redis) = prevents cross-instance duplication

Downstream caching = avoids unnecessary DB calls

This results in:

üöÄ 80‚Äì98% reduction in outbound microservice calls
üöÄ Faster response times
üöÄ Lower DB + service load
---------------------------------------------------------------------------------------------------------
4. Load Balancing and Scaling
Auto-Scaling: Implement auto-scaling mechanisms to dynamically adjust the number of service instances based on traffic, ensuring that no service gets overwhelmed.
Load Balancers: Use efficient load balancers to distribute incoming requests evenly across service instances, preventing any single instance from becoming a bottleneck.
Avoid Hotspots: Design the architecture to distribute the load evenly, avoiding scenarios where certain services or nodes become hotspots.
Client-Side Load Balancing (Java Microservices)

Spring Cloud LoadBalancer distributes traffic across service instances.

Step 1 ‚Äî Add dependencies
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-loadbalancer</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>

Step 2 ‚Äî Enable Feign + LoadBalancer
@SpringBootApplication
@EnableFeignClients
public class OrderServiceApplication {}

Step 3 ‚Äî Feign client with load balancing
@FeignClient(name = "payment-service")   // No URL ‚Üí LoadBalancer resolves it
public interface PaymentClient {
    @GetMapping("/pay/{orderId}")
    String processPayment(@PathVariable String orderId);
}


Spring Cloud LoadBalancer will distribute calls across:

payment-service-1
payment-service-2
payment-service-3

Step 4 ‚Äî Custom Load Balancing Strategy (Round-Robin / Random)
@Configuration
public class LoadBalancerConfig {

    @Bean
    ReactorLoadBalancer<ServiceInstance> loadBalancer(Environment env,
            ServiceInstanceListSupplier listSupplier) {
        String name = env.getProperty(LoadBalancerClientFactory.PROPERTY_NAME);
        return new RoundRobinLoadBalancer(listSupplier, name);
    }
}


‚úî Avoids hotspots by evenly distributing calls
‚úî Works automatically with service registry (Eureka/Consul)

2Ô∏è‚É£ Server-Side Load Balancing (NGINX + Java)
NGINX load balancer config:
upstream product_servers {
    server product-service-1:8080;
    server product-service-2:8080;
    server product-service-3:8080;
}

server {
    listen 80;

    location /products/ {
        proxy_pass http://product_servers;
    }
}


NGINX automatically distributes load across instances.

3Ô∏è‚É£ Auto Scaling (Kubernetes Horizontal Pod AutoScaler - HPA)
CPU-based autoscaling

hpa.yaml:

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: product-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: product-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70


‚úî Auto-scales when CPU > 70%
‚úî Prevents sudden overload and hotspots

Request-per-second based autoscaling (more advanced)
metrics:
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"

4Ô∏è‚É£ Avoid Hotspots: Use Consistent Hashing for Partitioning

If your service frequently accesses the same keys (hot keys), you can distribute evenly using hashing.

Example: consistent hashing to route a request to a shard:
@Component
public class ConsistentHashRouter {

    private final List<String> nodes = List.of("nodeA", "nodeB", "nodeC");

    public String route(String key) {
        int hash = Math.abs(key.hashCode());
        return nodes.get(hash % nodes.size());
    }
}


Usage:

String shard = router.route(customerId);
System.out.println("Route request to: " + shard);


üí° Even hot keys are uniformly distributed ‚Üí avoids hotspots.

5Ô∏è‚É£ Avoid Hotspots with Request-Level Load Shedding

Drop or delay requests when overloaded.

@Component
public class LoadShedder {

    private final AtomicInteger currentRequests = new AtomicInteger(0);
    private static final int MAX_ALLOWED = 100;

    public boolean allowRequest() {
        return currentRequests.incrementAndGet() <= MAX_ALLOWED;
    }

    public void done() {
        currentRequests.decrementAndGet();
    }
}


Controller:

@RestController
@RequiredArgsConstructor
public class ProductController {

    private final LoadShedder shedder;

    @GetMapping("/products/{id}")
    public ResponseEntity<?> getProduct(@PathVariable String id) {
        if (!shedder.allowRequest())
            return ResponseEntity.status(429).body("Too Many Requests");

        try {
            // real logic here
        } finally {
            shedder.done();
        }
    }
}


‚úî Stops the hotspot from collapsing the service.

6Ô∏è‚É£ Kafka Auto-Scaling Consumer Groups (Avoid Consumer Hotspots)

Use more partitions + more consumers.

Kafka consumer group example:
@KafkaListener(
    topics = "order-topic",
    groupId = "order-processors",
    concurrency = "5"
)
public void processOrder(String message) {
    System.out.println(Thread.currentThread().getName() + " ‚Üí " + message);
}


‚úî Spring Boot runs 5 parallel consumers
‚úî Kafka distributes load evenly
‚úî No single consumer becomes a hotspot

7Ô∏è‚É£ Load Balancing Database Writes Across Nodes (Shard Key)

Example: use customerId to select DB shard.

public class ShardSelector {

    public DataSource selectDB(String customerId) {
        int index = Math.abs(customerId.hashCode()) % 3;

        return switch (index) {
            case 0 -> shard1;
            case 1 -> shard2;
            default -> shard3;
        };
    }
}


‚úî Even distribution
‚úî Avoids all writes targeting the same DB node

‚úî Final Summary
Technique	Example	Purpose
Spring Cloud LoadBalancer	Round-robin Feign calls	Spread load across services
NGINX Load Balancing	Multiple servers block	Offload balancing from app
K8s HPA Autoscaling	CPU/RPS-based scaling	Auto-scale on demand
Consistent Hashing	Route keys ‚Üí shards	Avoid data hotspots
Kafka Concurrency	concurrency="5"	Parallel consumers
Load Shedding	Reject excess traffic	Protect services
DB Sharding	Hash-based routing	Avoid DB hotspots
---------------------------------------------------------------------------------------------------------
5. Use Circuit Breakers and Timeouts
Circuit Breakers: Implement circuit breakers to prevent cascading failures and reduce the impact of slow or failing services by quickly failing requests and avoiding retries.
Timeout Settings: Set appropriate timeouts for service calls to avoid long waits in case of service failure or slow responses, allowing the system to recover more quickly.

